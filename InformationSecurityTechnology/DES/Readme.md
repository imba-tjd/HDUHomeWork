# 实验一&二：DES分组密码算法

## 实验内容

1. 阅读、分析DES分组密码源程序。
2. 调用DES分组密码源程序中的相关函数，完成8字节的明文加密成8字节的密文，并完成解密。
3. 调用DES分组密码源程序中的相关函数，设计一个文件加密器，可以加密任意长度的文件，并密文文件可解密还原回原明文文件。
4. 调用DES分组密码源程序中的相关函数，设计支持CBC模式的一个文件加密器，可以加密任意长度的文件，并密文文件可解密还原回原明文文件。
5. 调用DES分组密码源程序中的相关函数，设计支持CFB模式的一个文件加密器，可以加密任意长度的文件，并密文文件可解密还原回原明文文件。

## DES.c 分析

此文件是老师提供的，不过貌似老师也是从网上下的。所有的函数都有简单的作用说明，理解起来不难。基本上最终要用的只有：

* `DES_MakeSubKeys`：接受64位二进制的密码，返回子密钥
* `DES_EncryptBlock` 和 `DES_DecryptBlock`：8字节明文与密文的转换；第二个参数需要使用上一行产生的子密钥

其中 `DES_DecryptBlock` 内部已经反向使用了子密钥，无需自己交换一遍。

此代码还有一些缺陷：

1. 滥用 `ElemType`：理论上 `subKeys` 的类型和 `cipherText` 的类型是不能用同一个自定义类型的；而 `plainText` 的类型就应该直接是char，不能是 `ElemType`。这导致typedef的意义大打折扣。
2. `DES_ROL` 函数中对有重叠的部分使用了 `memcpy` 函数，虽然因为是向前shift，没有出bug，但这样不符合参数指针的restrict约定。严格来说有重叠的部分应该使用 `memmove` 函数。
3. `#include "memory.h"` 是非标准库，应该使用 `<string.h>`。
4. 完全没有使用const的意识，导致我进一步实现代码时const转非const会报warning，连带着我也没法用了。
5. 返回的int毫无意义，全部是return 0。

## Common.c 分析

注意到三种加密方式大部分内容都是相同的，考虑提取出来写成 `Common.c`。为了不改变 `DES.c`，我把 `#infndef` 放在了include时，实际上一般要放在 `DES.c` 里面的。

产生子密钥时，先把7位明文密钥转换为二进制，可调用DES.c已提供的函数；再用 `DES_MakeSubKeys` 产生16个子密钥。可改进的地方是明文密钥长度大于7位怎么处理，可以考虑Hash后取低56位即可；但这个应该在 `MakeSubKeys` 里处理才对，我这个TODO写在 `InitContext` 里懒得改了。

因为函数调用的签名太长，考虑把所有参数提取到结构体中，参数用结构体指针。

问题最关键的地方，就是读文件有可能无法一次全部读完，必须处理好后再循环读下一次。ECB还好，但另外两种加密方式会依赖前一次的加密结果，所以需要引入pre数组，每一轮加密后把下一轮需要的数据复制过去。其次就是如果读到的数据不是8的倍数，则需要填充'\0'。

`DES_Encrypt` 的函数签名已经固定，直接调用无法动态指定要使用哪种加解密函数。我使用的是全局函数指针加Assert非NULL达到的，但这样会产生副作用。或者可以用函数声明，在算法文件实现中直接返回/使用具体的函数。

### fread 和 fwrite 的坑

1. `fread` 和 `fwrite` 处理的流必须以二进制打开，否则fread到ASCII码为26的字符时就会停止读取。测试见 `FModeTest.c`。
2. 文本文件最后没有'\0'，fread也不会读出来；fwrite把'\0'写进去会导致出现菱形乱码。
3. 为了解决2，我使用fprintf的%s，或fputs写入文件，则会自动到'\0'截止。但此时文件是二进制模式打开的，不知道是否会有问题，我暂时测试是没问题的。
4. 如果按照3操作，fread读入的是8的倍数，会导致末尾没有'\0'，因此这时必须加8个'\0'；且fread最多只能读取*BUFSIZ-1*个。
5. 也可以考虑从length往回检查，遇到'\0'就--。在 `ECB_2.c` 中进行了测试。

## CBC.c

本来解密是可以并行的，但我这样使用pre，就只能串行处理了。

## CFB.c

本来初始向量要经过一次位移的，但老师说本次实验可以不做。理论上加密器接收Length位，那Length就等于8吧，那n就必须小于8，感觉效率会有点低。

## ECB_2.c

一开始没看清楚要求，只实现了加密任意长度的字符串的程序。且当时没有布置第二次实验，导致代码耦合程度有点高。

不过 `MakeSubKeys` 是在这时实现的；此时还测试了直接把字符串字面量赋给char[]与一个个初始化的区别。

本来觉得加密任意长度对处理文件没有多大帮助，因为读文件后的buffer大小是固定的，我相当于把处理8字节的函数封装成了处理512字节函数，仍然需要循环读文件。

但现在觉得好像也差不多啊。为什么重构以后那么复杂呢，就是用了一个Context？于是干脆又手动实现了一遍文件的加解密。耦合程度确实很高。因为count是在实际算法函数中处理的，写入时要重新调整一下。

还试了一下using，感觉一般般吧，这样连续使用两个时错误处理会有问题。
